
------------------------------------
*            Demultiplex           *
------------------------------------

Run interactive session in talaps:
$ srun --account=bgmp --partition=bgmp --nodes=1 --ntasks-per-node=1 --time=1:00:00 --cpus-per-task=1 --pty bash

++++++++++++++++++++++++++++++++++++++++++++++++++++++
+ Part 1 â€“ Quality Score Distribution per-nucleotide +
++++++++++++++++++++++++++++++++++++++++++++++++++++++

------------------------------------------------------
--> 07/26/2022 <--
------------------------------------------------------
Initial data exploration:
used:
$ zcat 1294_S1_L008_R1_001.fastq.gz | less -S
to take a precursory look at the fastq file
Don't do a wc -l on the login node, if we want a line count, do it in an interactive session
the file is more than 300 million reads
$ ls -lah
    total 47G
    drwxrwsr-x+  3 coonrod  bgmp 8.0K Jul 30  2018 .
    drwxrws--x+ 38 sdwagner bgmp 8.0K Jul  1 10:55 ..
    -rw-rwxr--+  1 coonrod  bgmp  20G Jul 30  2018 1294_S1_L008_R1_001.fastq.gz
    -rw-rwxr--+  1 coonrod  bgmp 2.6G Jul 30  2018 1294_S1_L008_R2_001.fastq.gz
    -rw-rwxr--+  1 coonrod  bgmp 2.8G Jul 30  2018 1294_S1_L008_R3_001.fastq.gz
    -rw-rwxr--+  1 coonrod  bgmp  23G Jul 30  2018 1294_S1_L008_R4_001.fastq.gz
    drwx--S---+  2 coonrod  bgmp 8.0K Jul  1 16:08 demultiplexed
    -rwxrwxr-x+  1 sdwagner bgmp  631 Aug  9  2021 indexes.txt
    -rw-rwxr--+  1 coonrod  bgmp  327 Aug 16  2017 README.txt

these are gigantic files. 
to get the read length:
    $ zcat 1294_S1_L008_R1_001.fastq.gz | head -2 | tail -1 | wc
            1       1     102 #include new line character
    $ zcat 1294_S1_L008_R2_001.fastq.gz | head -2 | tail -1 | wc
            1       1     9
    $ zcat 1294_S1_L008_R3_001.fastq.gz | head -2 | tail -1 | wc
            1       1     9
    $ zcat 1294_S1_L008_R4_001.fastq.gz | head -2 | tail -1 | wc
            1       1     102

First read in each file from same location, headers all look the same except for counter [1,4]
Must read all at the same time. 
The indexes / barcodes will be found at the beginning and ends of the line?
is it the barcode itself at the beginning and rev comp at the end?
taking a look at one of the barcodes:
$ zcat 1294_S1_L008_R4_001.fastq.gz | grep "^CACTTCAC"
    CACTTCACCTAGAAAGTGCAAAATTCTTTGTTTTATGAATAAAATATAAGATAACACAAAATGTTTCAGAATGTATAGCCTTTGTTGGTTGGAGATGATTT
    CACTTCACTCTGTACCTGTAGCAAGGTCTGCCAACTCTATGGCTGCCGCACATGCATCTGGCCCTCCCTCTCTGTCCTGGGGTCCTCAGCGTGCTGTCTCC
    CACTTCACGAGAGGACAAATGCCACCTCTCAGCTGCATCTTGAAGCTGGTCACTTCTGGGTCTGTGGCAGGCATTCGTCAATGGCCCAGTGCAGTTCTCTG

i don't see the barcode at the end though...

to test whether it's phred 33 or 64:
$ zcat 1294_S1_L008_R1_001.fastq.gz | sed -n '4~4p' | grep -E "[a-z]+"

this did not return any results, so there are no lower case letters, which would indicate the encoding is 33

Also, # are only in 33, not 64, so it's another one to grep for. 

wrote rev_comp function in both bioinfo.py and python script for qscore Distribution

modified PS4 and PS9 scripts to calculate mean quality scores of a position from fq files
ran python script using sbatch on talapas
i forgot to time the runs. 

these are the runs:
    $ sbatch qdist.srun /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R1_001.fastq.gz 101 6
    Submitted batch job 21725458
    $ sbatch qdist.srun /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R4_001.fastq.gz 101 7
    Submitted batch job 21725461
    $ sbatch qdist.srun /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R2_001.fastq.gz 8 8
    Submitted batch job 21725462
    $ sbatch qdist.srun /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R3_001.fastq.gz 8 9
    Submitted batch job 21725463

    #!/bin/bash
    #SBATCH --partition=bgmp            ### Partition (like a queue in PBS)
    #SBATCH --job-name=qdist            ### Job Name
    #SBATCH --output=qdist_%j.out        ### File in which to store job output
    #SBATCH --error=qdist_%j.err         ### File in which to store job error messages
    #SBATCH --time=0-02:00:00           ### Wall clock time limit in Days-HH:MM:SS
    #SBATCH --nodes=1                   ### Number of nodes needed for the job
    #SBATCH --ntasks-per-node=1         ### Number of tasks to be launched per Node
    #SBATCH --account=bgmp              ### Account used for job submission

While it's running, moving onto next part to count the number of N in the files
$ zcat /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R1_001.fastq.gz | sed -n '4~4p'| grep -o "N" | grep -c

starting some new runs without 
        #SBATCH --time=0-02:00:00           ### Wall clock time limit in Days-HH:MM:SS
and with the timers and directing .err and .out files into directory output/

both runs of index files finished, with runtimes of around 54 minutes. 
this was job job21725647 and job21725648, which were hist 12 and 13, respectively. 
compared to the other two index runs, hist8 and hist9, they look the same for the correct files. 

the first two bio runs without the timer don't seem to have output a histogram and also seem to have exited the queue. 
too bad i don't know what happened bc the .out and .err are not super helpful :(

luckily, the most recent two bio runs, 21725645 and 21725643 are still going, this is at 5 hrs and 7 minutes now.

